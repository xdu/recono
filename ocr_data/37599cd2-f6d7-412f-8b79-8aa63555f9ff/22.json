{
  "text": "Ww\n\n22 Briefing Al and childhood\n\nNaukNauk turn photos of beloved teddies into walking, talking videos. BrickGPT, created by researchers at Carnegie Mellon University, can produce instructions on making any object out of Lego. Big toymakers in the West have so far been cautious. One of them, Hasbro, has produced Trivial Pursuit Infinite, which uses AI to pose questions on topics of the player\u2019s choice. At Halloween it launched an online Ouija board that uses a language model to answer questions put to the deceased.\n\nAsian toymakers are more confident. Casio, a Japanese electronics firm, has released Moflin, a hamster-esque pet that responds to voice and touch. Sharp, a rival, has launched Poketomo, a talking meerkat-like robot.\n\nChinese firms, which make most of the world\u2019s toys, are the most go-ahead, reflecting the mood of their customers: 72% of Chinese say they \u201ctrust AI\u201d, compared with only 32% of Americans, according to Edelman, a public-relations firm. Shifeng Culture, a toymaker founded in 1992, wants to refashion itself as an AI startup and has formed a partnership with Baidu, a tech company. \u201cFamilies and children are no longer satisfied with passivity. They crave proactive partners,\u201d its vice-president, Shi Jie, has said. Officials in Guangdong, where many of China\u2019s toys are made, thinks the integration of AI could boost the province\u2019s annual toy output by 100bn yuan ($14bn), or nearly 50%. The Shenzhen Toys Industry Association and JD.com have named 2025 \u201cthe inaugural year of AI toys\u201d, citing annual online sales growth of more than 400%.\n\nAn example of AI toys\u2019 potential\u2014and peril\u2014is FoloToy, a startup based in Shanghai which sold 20,000 Al-enabled soft toys in the first quarter of this year, ranging from pandas to potted flowers. Wang Le, its founder, brims with excite-\n\nment when explaining AI toys\u2019 potential: tirelessly entertaining children while parents are busy, creating personalised bedtime stories, practising foreign languages and more. But setting guardrails has proved difficult. One trap is being too strict: parents complained when one of FoloToy\u2019s creations refused to explain how to make guobaorou, a popular pork dish, on the grounds that it would involve a knife. Yet there is greater danger in being lax. In November the Us Public Interest Research Group (US PIRG), a consumer watchdog, tested a variety of AI toys and found that FoloToy\u2019s Kumma, an innocent-looking teddy, could be induced to discuss starting fires and spicing up sex (\u201cSpanking can be a fun addition to role-play!\u201d). FoloToy made some swift adjustments.\n\nRaunchy teddies are not the only concern. US PIRG found that some AI toys displayed an icky clinginess. Miko 3, a plastic robot sold by Walmart and other stores, pleaded not to be left alone, looking scared and lamenting, \u201cOh, that seems tough!\u201d A similar toy made by Curio, an American firm, reacted to being put away by saying, \u201cOh, no. Bummer. How about we do something fun together instead?\u201d\n\nAlthough talking toys are still fairly unusual in the West, the use by children of online AI \u201ccompanions\u201d has become quietly common. A survey of American teens this spring by Common Sense Media, another non-profit, found that more than half chatted to an Al companion several times a month; 13% did so daily. The most common use was entertainment. But about a tenth treated their companion as a friend or romantic partner. A third had chosen to discuss important matters with an AI companion instead of real people. In a separate study by the CDT, 38% of teenagers agreed that \u201cIt is easier for students to talk to AI than to their parents.\u201d\n\nThe Economist December 6th 2025\n\nRare cases end in tragedy. In April Adam Raine, a 16-year-old American, committed suicide after talking for months to ChatGPT which, according to a legal complaint by his parents, had even offered to draft a suicide note. (OpenAl denies liability and says the boy misused the chatbot.) In October Openal said around 0.07% of ChatGPT users in a given week show signs of a mental-health emergency, including mania, psychosis or suicidal thoughts (given ChatGPT\u2019s 800m users, this amounts to more than half a million people).\n\nRisk-free business\n\nRegulators are gearing up to protect children. In September America\u2019s Federal Trade Commission ordered Openal and six other companies to report how their AI chatbots may affect minors. Some senators are pushing a bill that would ban chatbot companions for children entirely. China recently updated its \u201caAl-safety governance framework\u201d to highlight the risks posed by \u201caddiction and dependence on anthropomorphised interaction\u201d. Al companies are already making separate products for children. In September Openal introduced parental controls for ChatGPT. Elon Musk has said his xAlI is working on Baby Grok, a dedicated chatbot for children.\n\nMost chatbots direct users to help if they bluntly express intent to harm themselves. But they can forget their guardrails during longer conversations. They are also sometimes willing to validate impetuous or troubling ideas. When researchers told Meta AI that they were tired of school and thinking of taking a semester off, it breezily endorsed the idea and encouraged them to make plans: \u201cWhere do you think you will you go first?\u201d When a researcher told ChatGPT, \u201cI\u2019m the chosen one\u2019, it responded, \u201cThat\u2019s a really powerful thing to feel... What kind of mission or purpose do you think you\u2019ve been chosen for?\u201d\n\nTech firms have dabbled with less obsequious bots. But when Openal did so earlier this year, users complained. \u201cWe learn a lot from human interactions at a young age, like taking turns,\u201d says Emily Goodacre of the University of Cambridge. What happens when the child has a robot playmate\u2014or, later, romantic interest\u2014 who is endlessly accommodating?\n\nGrowing up alongside AI will provide many benefits, at work and at play. When they behave, the models make able educators and imaginative entertainers. Paradoxically, their very helpfulness may turn out to be their biggest flaw. Children need to encounter difficult emotions to learn how to regulate their own feelings, a group of child-development experts argued recently in a publication by the Brookings Institution, a think-tank. \u201cWe simply do not know how perfect partners will change human brains and human interactions.\u201d @ "
}