{
  "text": "64 Business\n\nfranchises that span merchandise, films and in-person experiences. Others, including Mattel, which turned Barbie into a boxoffice hit in 2023, have proved that popular toys can be used as the starting point for such franchises.\n\nPop Mart is experimenting with this. Pop Land, a theme park it opened in Beijing in 2023, lets visitors interact with characters including Labubus. It may open more. The company also has plans to launch a Labubu animated series, and in\n\nJune it established its own film studio. So far, Pop Mart\u2019s ability to make money from more than just selling toys has been limited. Less than a tenth of its revenue comes from licensing, reckons Jeff Zhang of Morningstar, a research firm. But that share will probably rise as the company invests in developing its franchises.\n\nWith great success, however, often comes political scrutiny\u2014especially in China. The Communist Party, which has focused more on supporting advanced\n\nBARTLEBY Face off\n\nThe Economist November 8th 2025\n\nmanufacturing than fostering consumer brands, has lately become fascinated with the Labubu phenomenon. Its propaganda department has met Pop Mart executives and asked why its toys are not more Chinese in nature. The company has been forced to explain that overtly Chinese products do not sell well abroad, according to a person privy to the discussions. As Pop Mart grows bigger still, China\u2019s government may be unable to resist the urge to meddle. @\n\nShould facial analysis help determine whom companies hire?\n\n| har ca APPEARING for a job interview and, without saying a single word, being told that you are not getting the role because your face didn\u2019t fit. You would assume discrimination, and might even contemplate litigation.\n\nBut what if bias was not the reason? What if your face gave genuinely useful clues about your probable performance at work? That question is at the heart of a recent research paper from Marius Guenzel of the University of Pennsylvania and his co-authors. The possibility that it does raises larger questions about algorithmic decision-making and how humans perceive fairness.\n\nPersonality assessments are an accepted part of recruitment processes. They normally involve candidates taking surveys and guessing what counts as a good answer. Yet previous research suggests that personality types can be encoded in facial features, and that artificial intelligence (AI) can spot them. So Mr Guenzel and his co-authors used an algorithm to analyse the pictures of 96,000 MBA graduates, and extract what they call the \u201cPhoto Big Five\u201d\u2014as they rename the Big Five personality traits of agreeableness, conscientiousness, extraversion, neuroticism and openness. (Before you head to the mirror, it\u2019s not obvious what the AI is seeing.)\n\nThey then used data on these individuals\u2019 labour-market outcomes to see whether the Photo Big Five had any predictive power. The answer, they conclude, is yes: facial analysis has useful things to say about a person\u2019s post-MBA earnings and propensity to move jobs, among other things.\n\nThere are plenty of caveats. The predictive power of the Photo Big Five shouldn't be exaggerated; the authors say it is only an incremental source of\n\ninformation on candidates. The field of Al facial analysis is young, and has been at the centre of methodological firestorms in the past. And even if techniques were flawless, adoption is likely to be slow. Anti-discrimination laws mean that there are obvious legal risks associated with making any decisions based on facial characteristics. Manish Raghavan of the MIT Sloan School of Management notes that companies are wary of using AI for facial analysis (though he worries more about bias infecting chatbot summaries of candidates\u2019 Cvs or LinkedIn profiles.)\n\nBut suppose that all these objections were surmountable. If your face could tell a prospective employer something useful, without discriminating on grounds of protected characteristics, then firms would have a strong incentive to analyse it. There would still be questions, though. The authors give an example: \u201cAmong white male job candidates, is it ethical to screen out individuals whose faces predict less desirable personalities?\u201d\n\nYou could make the case that this would be fine. After all, plenty of decisions\n\nare already being taken on the basis of physical appearance. There is a height premium in hiring, for example, which makes it more likely that a taller person will get chosen than a shorter one. Some might argue that face-based analysis is more meritocratic than processes which reward, say, educational attainment. Kelly Shue of the Yale School of Management, one of the new paper\u2019s authors, says they are now looking at whether AI facial analysis can give lenders useful clues about a person\u2019s propensity to repay loans. For people without access to credit, that could be a blessing.\n\nEven setting aside the risk of bias, though, there are other big concerns. Some are obvious: aggregate patterns do not tell you how an individual will perform. Others are more insidious. An industry of coaches and self-help gurus is built on the idea that it is possible to control and modulate your behaviour. What\u2019s the point in self-improvement if your face is still going to give off the same signal that you're a dilettante?\n\nHow you react to this prospect also tells you something about AI and perceptions of fairness. It matters whether people retain a sense of agency. However good the algorithms get, a chance fora candidate to win over a human interviewer in a hiring process\u2014and for an interviewer to decide for themselves if they want to work with someone\u2014is likely to always be valued.\n\nMr Raghavan argues that people are more prepared to accept decisions based on immutable characteristics if there is clear causal logic. There are reasonable statistical grounds for younger drivers to pay higher car-insurance premiums, for example, or for older people to pay more for health care. For many, facial analysis will raise eyebrows. "
}